{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmau2002/EMDocs/blob/master/easyocr_batched_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OEJCNWohYHt",
        "outputId": "68fccff8-e286-4b84-adc6-71b90c1060c9"
      },
      "source": [
        "# easyocr test\n",
        "!pip install git+git://github.com/jaidedai/easyocr.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/jaidedai/easyocr.git\n",
            "  Cloning git://github.com/jaidedai/easyocr.git to /tmp/pip-req-build-p4ed2env\n",
            "  Running command git clone --filter=blob:none --quiet git://github.com/jaidedai/easyocr.git /tmp/pip-req-build-p4ed2env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuer Abschnitt"
      ],
      "metadata": {
        "id": "okeC6sWl6Kvy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqK8h_40iKTY",
        "outputId": "0b91efee-a497-4663-d002-5f6b4bab9812"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 20 14:07:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQYJMWFAhZnc"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import easyocr\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "\n",
        "if sys.version_info[0] == 2:\n",
        "    from six.moves.urllib.request import urlretrieve\n",
        "else:\n",
        "    from urllib.request import urlretrieve\n",
        "\n",
        "\n",
        "def test_single_and_batched_text_detection_and_prediction():\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    # test with easy logos to ensure same results\n",
        "    # test for single image with old api\n",
        "    result = reader.readtext(\n",
        "        \"https://pytorch.org/tutorials/_static/img/thumbnails/cropped/profiler.png\")\n",
        "    assert len(result), 1\n",
        "    assert result[0][1], 'PyTorch'\n",
        "    print(result)\n",
        "    print(\"Single image test with readtext successful\")\n",
        "\n",
        "    # test for single image with new api\n",
        "    result = reader.readtext_batched(\n",
        "        \"https://pytorch.org/tutorials/_static/img/thumbnails/cropped/profiler.png\")\n",
        "    assert len(result), 1\n",
        "    assert result[0][0][1], 'PyTorch'\n",
        "    print(result)\n",
        "    print(\"Single image test with readtext_batched successful\")\n",
        "\n",
        "    # test for a list of images in batch\n",
        "    img_path = [\n",
        "        \"https://pytorch.org/tutorials/_static/img/thumbnails/cropped/profiler.png\",\n",
        "        \"https://www.tensorflow.org/images/tf_logo_social.png\",\n",
        "        \"https://storage.googleapis.com/gd-wagtail-prod-assets/original_images/evolving_google_identity_2x1.jpg\"]\n",
        "\n",
        "    \"\"\"\n",
        "    all images in image list must be of the same size for batched inference\n",
        "        for eg, result = reader.readtext_batched(img_path) will fail here\n",
        "        so either resize all images to the same size before passing to readtext_batched\n",
        "        or call the func like so reader.readtext_batched(img_path, n_width=800, n_height=600)\n",
        "    \"\"\"\n",
        "    # warning, for better results, it is recommended to maintain aspect while resizing\n",
        "    result = reader.readtext_batched(img_path, n_width=800, n_height=600)\n",
        "    assert len(result), 3\n",
        "    assert result[0][0][1], 'PyTorch'\n",
        "    assert result[1][0][1], 'TensorFlow'\n",
        "    assert result[2][0][1], 'Google'\n",
        "    print(result)\n",
        "    print(\"Batched image test with readtext_batched successful\")\n",
        "\n",
        "    ############################################################################\n",
        "    # inference time test between sequential and batch processing\n",
        "    # batch processing will be faster when using GPU\n",
        "    ############################################################################\n",
        "    # pre-download, load and resize images for inference time test\n",
        "    img_path = [\n",
        "        \"https://pytorch.org/tutorials/_static/img/thumbnails/cropped/profiler.png\",\n",
        "        \"https://www.tensorflow.org/images/tf_logo_social.png\",\n",
        "        \"https://storage.googleapis.com/gd-wagtail-prod-assets/original_images/evolving_google_identity_2x1.jpg\"]\n",
        "\n",
        "    cv2_images = []\n",
        "    for i, path in enumerate(img_path):\n",
        "        tmp, _ = urlretrieve(path)\n",
        "        cv2_img = cv2.resize(cv2.imread(tmp), (800, 600))\n",
        "        cv2_images.append(cv2_img)\n",
        "        os.remove(tmp)\n",
        "\n",
        "    img_repeat, num_loop = 5, 1\n",
        "    cv2_images = np.array(cv2_images)\n",
        "    # np repeat to get a batch of 15 images, getting arr 15,600,800,3\n",
        "    cv2_images_repeat1 = np.repeat(cv2_images, repeats=img_repeat, axis=0)\n",
        "    cv2_images_repeat2 = cv2_images_repeat1.copy()\n",
        "    print(\n",
        "        f\"Running inference speed test with an image array of shape {cv2_images_repeat1.shape} for {num_loop} iterations\")\n",
        "\n",
        "    # sequential processing\n",
        "    # run batch processing test\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    itime = time.time()\n",
        "    for i in range(num_loop):\n",
        "        for img in cv2_images_repeat1:\n",
        "            reader.readtext(img)\n",
        "    print(\n",
        "        \"Single/Sequential image inference time per image: \" +\n",
        "        f\"{(time.time()-itime)/(num_loop*cv2_images_repeat1.shape[0]):.3f}s\")\n",
        "    # batched processing\n",
        "    reader = easyocr.Reader(['en'], cudnn_benchmark=True)\n",
        "\n",
        "    # warmup for batched inference on GPU, using same batch size for all subsequent inference\n",
        "    # cudnn benchmark should be set to True\n",
        "    # see this issue https://discuss.pytorch.org/t/model-inference-very-slow-when-batch-size-changes-for-the-first-time/44911\n",
        "    dummy = np.zeros([len(img_path) * img_repeat, 600, 800, 3], dtype=np.uint8)\n",
        "    reader.readtext_batched(dummy)\n",
        "\n",
        "    # run batch processing test\n",
        "    itime = time.time()\n",
        "    for i in range(num_loop):\n",
        "        reader.readtext_batched(cv2_images_repeat2)\n",
        "    print(\n",
        "        \"Batched image inference time per image: \" +\n",
        "        f\"{(time.time()-itime)/(num_loop*cv2_images_repeat1.shape[0]):.3f}s\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h4IKbmqiM_1",
        "outputId": "02d8ae07-40f1-4bc5-b692-1a70b1454627"
      },
      "source": [
        "test_single_and_batched_text_detection_and_prediction()\n",
        "test_single_and_batched_text_detection_and_prediction()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[([[158, 227], [546, 227], [546, 362], [158, 362]], 'PyTorch', 0.8182700892599657)]\n",
            "Single image test with readtext successful\n",
            "[[([[158, 227], [546, 227], [546, 362], [158, 362]], 'PyTorch', 0.8182700892599657)]]\n",
            "Single image test with readtext_batched successful\n",
            "[[([[218, 226], [719, 226], [719, 362], [218, 362]], 'PyTorch', 0.6865308673868696)], [([[155, 365], [643, 365], [643, 481], [155, 481]], 'TensorFlow', 0.9983146702913579)], [([[173, 190], [624, 190], [624, 418], [173, 418]], 'Google', 0.9934508520695108)]]\n",
            "Batched image test with readtext_batched successful\n",
            "Running inference speed test with an image array of shape (15, 600, 800, 3) for 1 iterations\n",
            "Single/Sequential image inference time per image: 0.304s\n",
            "Batched image inference time per image: 0.163s\n",
            "[([[158, 227], [546, 227], [546, 362], [158, 362]], 'PyTorch', 0.8182700892599657)]\n",
            "Single image test with readtext successful\n",
            "[[([[158, 227], [546, 227], [546, 362], [158, 362]], 'PyTorch', 0.8182700892599657)]]\n",
            "Single image test with readtext_batched successful\n",
            "[[([[218, 226], [719, 226], [719, 362], [218, 362]], 'PyTorch', 0.6865308673868696)], [([[155, 365], [643, 365], [643, 481], [155, 481]], 'TensorFlow', 0.9983146702913579)], [([[173, 190], [624, 190], [624, 418], [173, 418]], 'Google', 0.9934508520695108)]]\n",
            "Batched image test with readtext_batched successful\n",
            "Running inference speed test with an image array of shape (15, 600, 800, 3) for 1 iterations\n",
            "Single/Sequential image inference time per image: 0.313s\n",
            "Batched image inference time per image: 0.164s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR1SCtDfilqp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}